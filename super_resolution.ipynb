{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import math\n",
    "import copy\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model import UNet, ExponentialMovingAverage\n",
    "from dsr import DSRDataset\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('./dsr/')\n",
    "\n",
    "with open(root / 'train_valid_test_split.json', 'r') as f:\n",
    "    split = json.load(f)\n",
    "    \n",
    "train_dataset = DSRDataset(root, split['train'])\n",
    "val_dataset = DSRDataset(root, split['test'])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=2,\n",
    "    shuffle=True,\n",
    "    prefetch_factor=2\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=2,\n",
    "    shuffle=True,\n",
    "    prefetch_factor=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "images = next(iter(train_loader))\n",
    "lowres_images = images[0].numpy()\n",
    "highres_images = images[1].numpy()\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Time taken to get next batch of images: {elapsed_time} seconds\")\n",
    "\n",
    "print(lowres_images.shape)\n",
    "print(highres_images.shape)\n",
    "\n",
    "print('mean:', highres_images.mean())\n",
    "print('variance:', highres_images.var())\n",
    "print('min:', highres_images.min())\n",
    "print('max:', highres_images.max())\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10, 20), nrows=4, ncols=2)\n",
    "for i in range(4):\n",
    "    ax = axes[i]\n",
    "\n",
    "    lowres_image = (lowres_images[i] + 1) / 2\n",
    "    highres_image = (highres_images[i] + 1) / 2\n",
    "\n",
    "    ax[0].imshow(lowres_image.transpose(1, 2, 0))\n",
    "    ax[0].set_title('Upscaled Image')\n",
    "\n",
    "    ax[1].imshow(highres_image.transpose(1, 2, 0))\n",
    "    ax[1].set_title('Original Image')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net\n",
    "\n",
    "![Example Image](unet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_diffusion.model import UNet\n",
    "from simple_diffusion.scheduler import DDIMScheduler\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "unet = UNet(in_channels=6).to(device)\n",
    "ema = ExponentialMovingAverage(copy.deepcopy(unet).requires_grad_(False))\n",
    "optimizer = torch.optim.AdamW(unet.parameters(),lr=1e-3,betas=(0.9, 0.99),weight_decay=0.0)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "criterion = nn.MSELoss()\n",
    "epochs = 50\n",
    "T = 2000\n",
    "diffusion_scheduler = DDIMScheduler(beta_schedule=\"cosine\") #DiffusionScheduler(T, schedule_type='linear')\n",
    "tensorboard_path=\"./runs/diffusion-2M-test\"\n",
    "\n",
    "num_params = sum(p.numel() for p in unet.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters:\", num_params, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from train import train\n",
    "\n",
    "train(unet, ema, diffusion_scheduler, train_loader, val_loader, epochs, device, optimizer, scheduler, criterion, tensorboard_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(unet.state_dict(), 'dsr_sr_cos2.pth')\n",
    "#unet.load_state_dict(torch.load('dsr_sr_cos.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(val_loader))\n",
    "X = X[4].unsqueeze(0).to(device)\n",
    "y = y[4].to(device)\n",
    "\n",
    "samples = diffusion_scheduler.generate(unet, X)\n",
    "\n",
    "X = (X + 1) / 2\n",
    "y = (y + 1) / 2\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(X[0].permute(1, 2, 0).cpu().numpy())\n",
    "ax[0].set_title(\"Condition image\")\n",
    "\n",
    "ax[1].imshow(samples[-1][0].permute(1, 2, 0).cpu().numpy())\n",
    "ax[1].set_title(\"Sample image\")\n",
    "\n",
    "ax[2].imshow(y.permute(1, 2, 0).cpu().numpy())\n",
    "ax[2].set_title(\"Target image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.axis('off')\n",
    "\n",
    "def update(i):\n",
    "    if i < len(samples):\n",
    "        image = np.clip(samples[i][0].detach().numpy(), 0, 1)\n",
    "    else:\n",
    "        last_frame_index = len(samples) - 1\n",
    "        image = np.clip(samples[last_frame_index][0].detach().numpy(), 0, 1)\n",
    "        \n",
    "    image = np.concatenate((X[0].cpu().numpy(), image), axis=2)\n",
    "    ax.imshow(np.transpose(image, (1, 2, 0)))\n",
    "    \n",
    "ani = animation.FuncAnimation(fig, update, frames=len(samples) + 60, interval=60)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save('denoising_sr.gif', writer='imagemagick', fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
