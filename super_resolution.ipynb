{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import math\n",
    "import copy\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model import UNet\n",
    "from dsr import DSRDataset\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from srd import SuperResolutionDataset\n",
    "\n",
    "train_dataset = SuperResolutionDataset(data_path='flowers/train', resolution=128)\n",
    "val_dataset = SuperResolutionDataset(data_path='flowers/valid', resolution=128)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('./dsr/')\n",
    "\n",
    "with open(root / 'train_valid_test_split.json', 'r') as f:\n",
    "    split = json.load(f)\n",
    "    \n",
    "train_dataset = DSRDataset(root, split['train'], resolution=256)\n",
    "val_dataset = DSRDataset(root, split['test'], resolution=256)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=2,\n",
    "    shuffle=True,\n",
    "    prefetch_factor=2\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=2,\n",
    "    shuffle=True,\n",
    "    prefetch_factor=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "images = next(iter(train_loader))\n",
    "lowres_images = images[0].numpy()\n",
    "highres_images = images[1].numpy()\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Time taken to get next batch of images: {elapsed_time} seconds\")\n",
    "\n",
    "print(lowres_images.shape)\n",
    "print(highres_images.shape)\n",
    "\n",
    "print('mean:', highres_images.mean())\n",
    "print('variance:', highres_images.var())\n",
    "print('min:', highres_images.min())\n",
    "print('max:', highres_images.max())\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10, 20), nrows=4, ncols=2)\n",
    "for i in range(4):\n",
    "    ax = axes[i]\n",
    "\n",
    "    lowres_image = (lowres_images[i] + 1) / 2\n",
    "    highres_image = (highres_images[i] + 1) / 2\n",
    "\n",
    "    ax[0].imshow(lowres_image.transpose(1, 2, 0))\n",
    "    ax[0].set_title('Upscaled Image')\n",
    "\n",
    "    ax[1].imshow(highres_image.transpose(1, 2, 0))\n",
    "    ax[1].set_title('Original Image')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net\n",
    "\n",
    "![Example Image](unet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_diffusion.model import UNet\n",
    "from simple_diffusion.scheduler import DDIMScheduler\n",
    "\n",
    "torch.set_default_tensor_type(torch.HalfTensor)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "unet = UNet(hidden_dims=[16, 32, 64, 128], image_size=256).to(device).half()\n",
    "optimizer = torch.optim.AdamW(unet.parameters(),lr=1e-4,betas=(0.9, 0.99),weight_decay=0.0)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min') # log this to tensorboard, add patience\n",
    "criterion = nn.MSELoss()\n",
    "epochs = 50\n",
    "T = 2000\n",
    "diffusion_scheduler = DDIMScheduler(beta_schedule=\"cosine\") #DiffusionScheduler(T, schedule_type='linear')\n",
    "tensorboard_path=\"./runs/diffusion-2M-dsr-256R-cosine-1e-4\"\n",
    "\n",
    "num_params = sum(p.numel() for p in unet.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters:\", num_params, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from train import train\n",
    "\n",
    "train(unet, diffusion_scheduler, train_loader, val_loader, epochs, device, optimizer, scheduler, criterion, tensorboard_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(unet.state_dict(), 'dsr-sr.pth')\n",
    "unet.load_state_dict(torch.load('dsr_sr.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(val_loader))\n",
    "\n",
    "num_samples = X.shape[0]  # batch size\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "samples = diffusion_scheduler.generate(unet, X, batch_size=num_samples, num_inference_steps=100)\n",
    "samples = samples[-1]\n",
    "\n",
    "X = (X + 1) / 2\n",
    "y = (y + 1) / 2\n",
    "samples = (samples + 1) / 2\n",
    "\n",
    "fig, ax = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    ax[i, 0].imshow(X[i].permute(1, 2, 0).cpu().numpy())\n",
    "    ax[i, 0].set_title(\"Condition image\")\n",
    "\n",
    "    ax[i, 1].imshow(samples[i].permute(1, 2, 0).cpu().numpy())\n",
    "    ax[i, 1].set_title(\"Sample image\")\n",
    "\n",
    "    ax[i, 2].imshow(y[i].permute(1, 2, 0).cpu().numpy())\n",
    "    ax[i, 2].set_title(\"Target image\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.axis('off')\n",
    "\n",
    "def update(i):\n",
    "    if i < len(samples):\n",
    "        image = np.clip(samples[i][0].detach().numpy(), 0, 1)\n",
    "    else:\n",
    "        last_frame_index = len(samples) - 1\n",
    "        image = np.clip(samples[last_frame_index][0].detach().numpy(), 0, 1)\n",
    "        \n",
    "    image = np.concatenate((X[0].cpu().numpy(), image), axis=2)\n",
    "    ax.imshow(np.transpose(image, (1, 2, 0)))\n",
    "    \n",
    "ani = animation.FuncAnimation(fig, update, frames=len(samples) + 60, interval=60)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save('denoising_sr.gif', writer='imagemagick', fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
